\appendix
\chapter{}
\addcontentsline{toc}{chapter}{Anhang A}

\section{Notebook CIFAR-100 Subset Colorization}
\label{sec:nootebook_cifar_100}
\begin{longlisting}
  \begin{minted}{python}
    from __future__ import print_function, division
    import time
    import datetime
    import os
    import copy
    import csv

    import matplotlib.pyplot as plt

    # For conversion
    from skimage.color import lab2rgb, rgb2lab, rgb2gray
    from skimage import io

    import numpy as np
    import torch
    import torch.utils.data
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.optim import lr_scheduler
    from torch.optim.lr_scheduler import ReduceLROnPlateau
    import torchvision
    from torchvision import datasets, models, transforms

    use_gpu = torch.cuda.is_available()
    N_BINS = 324
    W_BIN  = np.sqrt(N_BINS).astype(int)

    cifar_data_train = datasets.CIFAR100(".", train=True, transform=transforms.Compose([
      transforms.RandomResizedCrop(32),
      transforms.RandomHorizontalFlip()
    ]), target_transform=None, download=True)

    cifar_data_val = datasets.CIFAR100(".", train=False, transform=transforms.Compose([
      transforms.Resize(32),
      transforms.CenterCrop(32)
    ]), target_transform=None, download=True)

    meta = np.load('cifar-100-python/meta', allow_pickle=True)

    def calculate_bin(a, b, width):
      return (width * b) + a

    '''
      Encode each pixel from the image into a bin

      Output: (W, H) where each value is a bin
    '''
    def encode_bins(ab_image, n_bins):
      x = np.linspace(0,1,W_BIN+1)
      indices = np.digitize(ab_image, x) - 1
      
      bins = np.vectorize(calculate_bin)(indices[:,:,0], indices[:,:,1], W_BIN)

      return bins

    def to_rgb(grayscale_input, ab_input):
      '''
        Convert to rgb
      '''
      color_image = torch.cat((grayscale_input, ab_input), 0).numpy() #combine channels
      color_image = color_image.transpose((1, 2, 0)) # rescale for matplotlib
      color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100
      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128
      color_image = lab2rgb(color_image)
      
      return (color_image * 255).astype(int)

    class GrayscaleDataLoader(torch.utils.data.Dataset):
      def __init__(self, dataset):
        self.images = dataset

      def __getitem__(self, index):
        image, target = self.images[index]
        
        img_original = np.asarray(image)

        # rgb to lab
        img_lab = rgb2lab(img_original)
        img_lab = (img_lab + 128) / 255
        img_ab = img_lab[:, :, 1:3]

        # form bins
        bins = torch.from_numpy(encode_bins(img_ab, N_BINS))

        #ab channels
        img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()

        # greyscale image
        img_original = rgb2gray(img_original)
        img_original = torch.from_numpy(img_original).unsqueeze(0).float()
        
        return img_original, img_ab, bins

      def __len__(self):
        return len(self.images)

    classes = [0, 23, 33, 47, 49, 52, 56, 59, 70, 71, 82, 96]

    def filter_image(image):
      if image[1] in classes:
        return image

    filtered_data_train = list(filter(None, map(filter_image, cifar_data_train)))
    train_images = GrayscaleDataLoader(cifar_data_train)

    filtered_data_val = list(filter(None, map(filter_image, cifar_data_val)))
    val_images = GrayscaleDataLoader(cifar_data_val)

    print(len(train_images))
    print(len(val_images))

    train_loader = torch.utils.data.DataLoader(train_images, batch_size=64, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_images, batch_size=64, shuffle=True)

    class Conv2dBlock(nn.Module):
      def __init__(self, D_in, n_filters, kernel_size=3):
        super(Conv2dBlock, self).__init__()

        # first layer
        self.conv1       = nn.Conv2d(D_in, n_filters, kernel_size, stride=1, padding=1)
        self.batch_norm1 = nn.BatchNorm2d(n_filters)

        # second layer
        self.conv2       = nn.Conv2d(n_filters, n_filters, kernel_size, stride=1, padding=1)
        self.batch_norm2 = nn.BatchNorm2d(n_filters)
      
      def forward(self, x):
        x = self.conv1(x)
        x = self.batch_norm1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = self.batch_norm2(x)
        out = F.relu(x)
      
        return out

    class Model(nn.Module):
      def __init__(self, n_out):
        super(Model, self).__init__()
        
        # Encoder
        self.conv1 = Conv2dBlock(1, 8)
        self.pool1 = nn.MaxPool2d(2, 2)

        self.conv2 = Conv2dBlock(8, 16)
        self.pool2 = nn.MaxPool2d(2, 2)

        self.conv3 = Conv2dBlock(16, 32)

        # Decoder
        self.upconv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)

        self.conv4   = Conv2dBlock(32, 16)
        self.upconv2 = nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1)

        self.conv5   = Conv2dBlock(16, 8)
        self.conv6   = nn.Conv2d(8, n_out, kernel_size=1, stride=1, padding=0)
        
      def forward(self, x):
        c1 = self.conv1(x)
        x  = self.pool1(c1)

        c2 = self.conv2(x)
        x  = self.pool2(c2)

        c3 = self.conv3(x)

        u1 = self.upconv1(c3)
        x  = torch.cat([u1, c2], dim=1)

        x = self.conv4(x)
        u2 = self.upconv2(x)
        x  = torch.cat([u2, c1], dim=1)

        x = self.conv5(x)
        out = self.conv6(x)

        return out

    # Classify mode colors to bins
    dataset_bin_colors = {i: [[], []] for i in range(N_BINS)}

    def get_dataset_bin(colors_dict, mode='mode'):
      _dict = copy.deepcopy(colors_dict)

      for bin in _dict:
        for channel, _ in enumerate(_dict[bin]):
          if (len(_dict[bin][channel]) > 0):
            if mode == 'mode':
              _dict[bin][channel] = np.max(np.array(_dict[bin][channel]))
            elif mode == 'mean':
              _dict[bin][channel] = np.mean(np.array(_dict[bin][channel]))
          else:
            _dict[bin][channel] = 0

      np.save(mode + '_color_bins_'+str(N_BINS)+'.npy', _dict)
      del _dict

    def add_to_dict(bin, a, b):
      dataset_bin_colors[bin][0].append(a)
      dataset_bin_colors[bin][1].append(b)

    def _encode_bins(ab_image):
      x = np.linspace(0,1,W_BIN+1)
      indices = np.digitize(ab_image, x) - 1
      indices = indices.transpose(1, 2, 0)
      
      bins = np.vectorize(calculate_bin)(indices[:,:,0], indices[:,:,1], W_BIN)
      np.vectorize(add_to_dict)(bins, ab_image[0,:,:], ab_image[1,:,:])

      return bins

    counter = 0

    for index, y in enumerate(train_loader):
      gray_images, ab_images, bins = y
        
      for i, ab in enumerate(ab_images):
        _encode_bins(ab)

    get_dataset_bin(dataset_bin_colors, 'mode')
    get_dataset_bin(dataset_bin_colors, 'mean')

    '''
      Return the mode of the predicted bin for each color chanel
    '''
    def decode_pixel(bin, T, dataset_bin_colors_mode, dataset_bin_colors_mean):
      a_mode = dataset_bin_colors_mode[bin][0]
      b_mode = dataset_bin_colors_mode[bin][1]

      a_mean = dataset_bin_colors_mean[bin][0]
      b_mean = dataset_bin_colors_mean[bin][1]

      if a_mode == 0:
        a_mode = assign_next_bin(bin, a_mode, 0, dataset_bin_colors_mode)

      if b_mode == 0:
        b_mode = assign_next_bin(bin, b_mode, 1, dataset_bin_colors_mode)

      if a_mean == 0:
        a_mean = assign_next_bin(bin, a_mean, 0, dataset_bin_colors_mean)

      if b_mean == 0:
        b_mean = assign_next_bin(bin, b_mean, 1, dataset_bin_colors_mean)
      
      a_distance = a_mode - a_mean
      b_distance = b_mode - b_mean

      a = a_mode - (a_distance * T)
      b = b_mode - (b_distance * T)

      return a, b

    '''
      Assign predicted color from next bin
    '''
    def assign_next_bin(bin, channel, index, colormap):
      counter = [1, -1]
      length = len(colormap) - 1

      while channel == 0:
        plus_index = bin + counter[0] if bin + counter[0] <= length else length
        channel = colormap[plus_index][index]

        if channel == 0:
          counter[0] += 1
          minus_index = bin + counter[1] if bin + counter[1] >= 0 else 0
          channel = colormap[minus_index][index]
          counter[1] -= 1

      return channel

    def deserialize_bins(bins, T, mode_path, mean_path):
      bins = bins.numpy()
      dataset_bin_colors_mode = np.load(mode_path, allow_pickle=True)
      dataset_bin_colors_mean = np.load(mean_path, allow_pickle=True)

      return np.array(np.vectorize(decode_pixel)(bins, T, dataset_bin_colors_mode, dataset_bin_colors_mean))

    '''
      A class from the PyTorch ImageNet tutorial
    ''' 
    class AverageMeter(object):
      def __init__(self):
        self.reset()
      def reset(self):
        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0
      def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def train(train_loader, model, criterion, optimizer, epoch, use_gpu):
      print('Starting training epoch {}'.format(epoch))
      model.train()

      # Prepare value counters and timers
      batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()

      end = time.time()
      for i, (input_gray, input_ab, bins) in enumerate(train_loader):
        bins = bins.squeeze(0)
        # Use GPU if available
        if use_gpu: input_gray, input_ab, bins = input_gray.cuda(), input_ab.cuda(), bins.cuda()

        # Record time to load data (above)
        data_time.update(time.time() - end)

        # Run forward pass
        output_bins = model(input_gray)
        loss = criterion(output_bins, bins)
        losses.update(loss.item(), input_gray.size(0))

        # Compute gradient and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Record time to do forward and backward passes
        batch_time.update(time.time() - end)
        end = time.time()

        # Print model accuracy -- in the code below, val refers to value, not validation
        if i % 25 == 0:
          print('Epoch: [{0}][{1}/{2}]\t'
                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
                'Data {data_time.val:.3f} ({data_time.avg:.3f})\t'
                'Loss {loss.val:.4f} ({loss.avg:.4f})\t'.format(
                  epoch, i, len(train_loader), batch_time=batch_time,
                data_time=data_time, loss=losses))

      print('Finished training epoch {}'.format(epoch))

      return losses.avg

    def validate(val_loader, model, criterion, epoch, use_gpu):
      model.eval()

      # Prepare value counters and timers
      batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()

      end = time.time()

      for i, (input_gray, input_ab, bins) in enumerate(val_loader):
        data_time.update(time.time() - end)
        bins = bins.squeeze(0)

        # Use GPU
        if use_gpu: input_gray, input_ab, bins = input_gray.cuda(), input_ab.cuda(), bins.cuda()

        # Run model and record loss
        output_bins = model(input_gray)
        loss = criterion(output_bins, bins)
        losses.update(loss.item(), input_gray.size(0))

        # Record time to do forward passes and save images
        batch_time.update(time.time() - end)
        end = time.time()

        # Print model accuracy -- in the code below, val refers to both value and validation
        if i % 25 == 0:
          print('Validate: [{0}/{1}]\t'
                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
                'Loss {loss.val:.4f} ({loss.avg:.4f})\t'.format(i, len(val_loader), batch_time=batch_time, loss=losses))

      print('Finished validation.')
      return losses.avg

    model = Model(324)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    if use_gpu:
      criterion = criterion.cuda()
      model = model.cuda()

    epochs = 150
    best_losses = 2.5

    output = csv.writer(open('train_log.csv', 'w'))
    output.writerow(['epoch', 'train_loss', 'val_loss'])

    with open('train_log.csv', 'w') as output:
      writer = csv.writer(output)
      writer.writerow(['epoch', 'train_loss', 'val_loss'])

      for epoch in range(60, epochs):
        if use_gpu and epoch > 0:
          model.cuda()
        # Train for one epoch, then validate
        train_loss = train(train_loader, model, criterion, optimizer, epoch, use_gpu)
        with torch.no_grad():
          val_loss = validate(val_loader, model, criterion, epoch, use_gpu)
          # scheduler.step(val_loss)
        writer.writerow([epoch, train_loss, val_loss])
        # Save checkpoint and replace old best model if current model is better
        print('Val Loss = {}'.format(val_loss))
        print('Best Loss = {}'.format(best_losses))
        if val_loss < best_losses:
          best_losses = val_loss
          torch.save(model.to('cpu').state_dict(), 'model-cifar-{}-{}-{:.3f}.pth'.format(N_BINS, epoch+1,val_loss))

    def evaluate(gray, ab_input, bins, model, temperature):
      model.eval()

      with torch.no_grad():
        bins = bins.squeeze(0)

        # Run model and record loss
        # add batch size 1 for single image
        output_bins = model(gray.unsqueeze(1))
        
        # remove batch size and get the max index of the predicted bin for each pixel
        color_image = to_rgb(
          gray,
          torch.from_numpy(
            deserialize_bins(
              output_bins.squeeze(0).argmax(0),
              temperature,
              'mode_color_bins_'+str(N_BINS)+'.npy',
              'mean_color_bins_'+str(N_BINS)+'.npy',
            ),
          ).float()
        )

      return color_image
  \end{minted}
\end{longlisting}