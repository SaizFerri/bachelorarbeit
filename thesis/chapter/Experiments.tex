\chapter{Experimente}
In diesem Kapitel werden Experimente mit den drei Datensätze durchgeführt. Ebenfalls werden verschiedene Hyperparameter getestet.

\section{Spiel-Datensatz Experimente}
\label{experimente:spiel}
Als erstes wird die Methode auf dem Spiel-Datensatz angewendet. Hiermit soll geprüft werden ob die Methode die erwartete
Ergebnisse liefert. Das U-Net wird für 100 Epochen mit Adam, eine Lernrate von 0.001 und die Cross Entropy Loss Function trainiert. Dieser
Einstellung erwies die besten Ergebnisse. Außerdem wurde ein Experiment mit 36 und ein mit 324 Bins durchgeführt, was kein Einfluss auf die 
Ergebnisse vorwies. Es kann davon ausgegangen werden, dass bei der niedrige Anzahl an möglichen Farben, ein Unterschied bei 36 und 324 Bins
nicht zu erkennen ist. Die unteren Ergebnissen wurden mit 324 Bins erstellt.

\begin{figure}[H]
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/30.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/31.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/42.png}
  \end{subfigure}
  \caption{Beispiele von sehr gute Ergebnisse aus dem Spiel-Datensatz}
  \label{image:gute-ergebnisse-toy-dataset}
\end{figure}

Bei den oberen Ergebnisse wurden alle Pixeln richtig klassifiziert, was bei der Größe des Datensatzes oft zu overfitting deutet.
Die unteren Ergebnissen zeigen dass das Model generalisiert und nicht overfited hat.

\begin{figure}[H]
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/581.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/712.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.32\textwidth]{resources/experiments/761.png}
  \end{subfigure}
  \caption{Beispiele von generalisierte Ergebnisse}
  \label{image:nicht-gute-ergebnisse-toy-dataset}
\end{figure}

Das Model zeigte bei einige Ergebnisse, Schwierigkeiten die Pixeln am Rand der geometrische Formen, richtig zu klassifizieren.
Dies tritt speziell auf die Kreise und Dreiecke wo die Ränder nicht aus glatte Linien bestehen. Des weiteren wurden die Farben mittels
den Durchschnitt für jeden möglichen Bin über alle Farben von jeden Trainingsbild rekonstruiert. Ein Unterschied zwischen der Modus und der 
Durchschnitt könnte nicht erkannt werden, da beide Werte gleich waren.
\\
Die Ergebnisse bestätigen dass das Binning und die Methode funktionieren. Anschließend wurden Experimente auf komplexere Bilder
von dem Subset von CIFAR-100 durchgeführt.

\section{CIFAR-100 Subset Experimente}\label{section:cifar-experimente}
Das Model wurde auf 12 Klassen von CIFAR-100 über 100 Epochen mit Adam, eine Lernrate von 0.001 und die Cross Entropy Loss Function
trainiert. Diese Einstellungen ergab sich als die beste Kombination von Hyperparameter, jedoch wurde das Training bei unter 50 Epochen unterbrochen
um overfitting zu verhindern.
% Um diesen Anstieg zu vermeiden, wurde ein Mechanismus eingeführt um die Lernrate bei einem bestimmten
% Faktor zu reduzieren wenn der Validation Loss nicht mehr sinkt oder sogar steigt. Dieser Mechanismus bietet PyTorch und wurde mit der 
% Klasse \textit{ReduceLROnPlateau} implementiert.

\begin{figure}[H]
  \centering
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/200_grayscale.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/200_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/200_t1.png}
  \end{subfigure}

  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/600_grayscale.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/600_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.24\textwidth]{resources/experiments/cifar/600_t1.png}
  \end{subfigure}
  \caption{Beispiele von gute Ergebnisse aus dem Subset von CIFAR-100 mit 324 Bins. Die erste Spalte beinhaltet das Graustufenbild, die zweite Spalte
  beinhaltet das Originale Bild und die letzte Spalte stellt das generierte Bild dar. Das generierte Bild wurde mit eine Temperatur von 1
  erzeugt, was bedeutet dass die rekonstruierte Farben den Durchschnitt aus jedem Bin repräsentieren.}
  \label{image:gute-ergebnisse-cifar}
\end{figure}

Die Experimente mit diesem Datensatz haben gezeigt dass die Anzahl der Bins bei der Auswahl an möglichen Farben die Ergebnisse beeinträchtigen.
Eine Erhöhung an Trainingszeit zwischen 36 und 324 Bins war nicht zu erkennen.

% TODO: Change image
\begin{figure}[H]
  \centering
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/702_grayscale.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/702_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/702_36_t1.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/702_t1.png}
  \end{subfigure}

  \caption{Einfluss von Anzahl der Bins auf die Ergebnisse. Das zweite Bild ist das originale, das dritte Bild wurde mit 36 Bins und ein
  Temperaturwert von 1 generiert und das vierte nur mit 324 Bins und ebenfalls mit ein Temperaturwert von 1.}
  \label{image:gute-ergebnisse-cifar}
\end{figure}

Um das Overfitting zu verhindern wurden Zahlreiche Experimente mit verschiedene Optimierer, Aktivierungsfunktionen und Lernraten durchgeführt.
Eine Ersetzung von ReLU durch Tanh zeigte ein stabilerer Trainingsverhalten aber eine Verschlechterung der Validation Loss. Leaky ReLU zeigte 
ein ähnliches Verhalten wie ReLU aber keine Verbesserung. Die Verwendung von RMSprop anstatt Adam zeigte eine langsamere Konvergenz Richtung Minimum.
Abschließend wurden die Anzahl der Filter in den Convolutional Layers halbiert was eine positive Wirkung auf das Training zeigte.   

\subsection{Experimente mit MSE Loss und ohne Binning}
Um die Performance von Klassifikation gegenüber Regression zu messen, wurde ein Model mit der MSE Loss Function trainiert. Dieses Model
wurde ebenfalls mit den gleichen Parameter wie das Klassifikationsmodell trainiert und hat beeindruckende Ergebnisse erreicht. Einige Ergebnisse
zeigten Blasse stellen im Vergleich zu das Klassifikationsmodell, der leuchtende Farben an den gleichen Stellen gezeigt hat.

\begin{figure}[H]
  \centering
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/311_grayscale.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/311_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/311_t1.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/cifar/311_regression.png}
  \end{subfigure}

  \caption{Vergleich von Klassifikation mit Binning gegenüber Regression. Das zweite Bild wurde mit 324 Bins und der Cross Entropy Loss generiert.
  Das dritte Bild wurde ohne Binning und mit einem MSE Loss generiert.}
  \label{image:mse-ergebnisse-cifar}
\end{figure}

\section{Landscape Datensatz Experimente}
Dieser Datensatz wurde anhand der Hyperparameter Optimierung von den CIFAR-100 Subset trainiert. Es wurde das größere Model für $128 \times 128$
Input Bilder angewendet. Das Model wurde ebenfalls für 36 und 324 Bins, mit dem Adam Optimizer, eine Lernrate von 0.001 und die Cross Entropy 
Loss Function für 60 Epochen trainiert. Das Model mit den besten Validation Loss wurde gespeichert um die Ergebnisse zu evaluieren. Außerdem
wurden den Einfluss der Temperaturwert und der Anzahl der Bins auf die Ergebnisse gemessen.
\\
\\
Das Model tendierte ebenfalls bei diesem Datensatz zum Overfitting. Um das zu verhindern wurden die gleiche Techniken wie bei CIFAR-100
angewendet, was keine bessere Ergebnisse geliefert hat. Eine Halbierung der Anzahl der Filter bei den Convolutional Layers erwiesen eine Verschlechterung
des Validation Loss und half nicht bei Overfitting. Eine Änderung der Optimierer zu RMSprop und die Ersetzung von ReLU für Tanh zeigten
einen stabileren Training aber keine Verbesserung der Validation Loss. Das Endgültige Model wurde trainiert bis der Validation Loss wieder stieg.

\begin{figure}[H]
  \centering
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/028/028_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/028/028_t0.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/028/028_t08.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/028/028_t1.png}
  \end{subfigure}

  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/736/736_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/736/736_t0.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/736/736_t08.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/736/736_t1.png}
  \end{subfigure}

  \caption{Ergebnisse mit 324 Bins. Die erste Spalte zeigt das Originale Bild, die zweite zeigt das generierte Bild mit einer Temperatur von 0,
  die dritte Spalte zeigt das generierte Bild mit einer Temperatur von 0.8 und die vierte Spalte zeigt das generierte Bild mit einer Temperatur 
  von 1}
  \label{image:gute-ergebnisse-own}
\end{figure}

Nach der Auswertung der Experimente würden 324 Bins und ein Temperaturwert von 0.8 bis 1 bevorzugt um die bestmöglichen Ergebnissen zu bekommen.

\begin{figure}[H]
  \centering
  \vspace{1cm}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/342/342_grayscale.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/342/342_original.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/36_bins/342/342_t1.png}
  \end{subfigure}
  \begin{subfigure}
    \centering
    \includegraphics[width=.235\textwidth]{resources/experiments/landscape/324_bins/342/342_t1.png}
  \end{subfigure}

  \caption{Ergebnisse mit 36 und 324 Bins. Die erste Spalte zeigt das Graustufenbild, die zweite zeigt das originale Bild,
  die dritte Spalte zeigt das mit 36 Bins generierte Bild mit einer Temperatur von 1 und die vierte Spalte zeigt das mit 324 Bins generierte 
  Bild mit einer Temperatur von 1}
  \label{image:bins-ergebnisse-own}
\end{figure}